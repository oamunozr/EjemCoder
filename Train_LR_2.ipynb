{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-blink",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar librerias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"ticks\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import joblib\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt.plots import plot_objective, plot_histogram, plot_evaluations\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, roc_curve, f1_score, accuracy_score, auc, balanced_accuracy_score, plot_confusion_matrix\n",
    "\n",
    "import shap\n",
    "\n",
    "\n",
    "def Interval(y_test, y_model, alpha = 5.0): #alpha = 5.0\n",
    "    # Realiza 100 muestreos de 1.000 datos para el calculo de metricas y su intervalo de confianza\n",
    "    roc_scores = list()\n",
    "    PR_scores = list()\n",
    "    for _ in range(100):\n",
    "        y_sample = y_test.sample(10000)\n",
    "        roc = roc_auc_score(y_sample, y_model.filter(items = y_sample.index, axis=0))\n",
    "        roc_scores.append(roc)\n",
    "        lr_precision, lr_recall, _ = precision_recall_curve(y_sample, y_model.filter(items = y_sample.index, axis=0))\n",
    "        lr_auc = auc(lr_recall, lr_precision) \n",
    "        PR_scores.append(lr_auc)\n",
    "    \n",
    "    lower_p = alpha / 2.0\n",
    "    upper_p = (100 - alpha) + (alpha / 2.0)\n",
    "    lower_roc = max(0.0, np.percentile(roc_scores, lower_p))\n",
    "    upper_roc = min(1.0, np.percentile(roc_scores, upper_p))\n",
    "    t1 = '({0:.2f}, {1:.2f})'.format(lower_roc, upper_roc)\n",
    "    lower_lr = max(0.0, np.percentile(lr_auc, lower_p))\n",
    "    upper_lr = min(1.0, np.percentile(lr_auc, upper_p))\n",
    "    t2 = '({0:.2f}, {1:.2f})'.format(lower_lr, upper_lr)\n",
    "    return t1#, t2\n",
    "\n",
    "def plot_ROC_AUC(model, X_test, y_test):\n",
    "    ns_probs = [0 for _ in range(len(y_test))]\n",
    "    lr_probs = model.predict_proba(X_test)[:, 1]\n",
    "    ns_auc = roc_auc_score(y_test, ns_probs)\n",
    "    lr_auc = roc_auc_score(y_test, lr_probs)\n",
    "    ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n",
    "    lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    ax.plot(ns_fpr, ns_tpr, linestyle='--', label='Curva ROC')\n",
    "    ax.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
    "    ax.set_xlabel('Tasa de falsos positivos')\n",
    "    ax.set_ylabel('Tasa de verdaderos positivos')\n",
    "    ax.set_title('Área bajo la curva ROC')\n",
    "    ax.legend()\n",
    "    \n",
    "def plot_AUC_PR(model, X_test, y_test):\n",
    "    lr_probs = model.predict_proba(X_test)[:, 1]\n",
    "    lr_precision, lr_recall, _ = precision_recall_curve(y_test, lr_probs)\n",
    "    lr_f1, lr_auc = f1_score(y_test, y_model), auc(lr_recall, lr_precision)\n",
    "    \n",
    "    print('Logistic: f1=%.3f auc=%.3f' % (lr_f1, lr_auc))\n",
    "    \n",
    "    no_skill = len(y_test[y_test==1]) / len(y_test)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    ax.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
    "    ax.plot(lr_recall, lr_precision, marker='.', label='Logistic')    \n",
    "    ax.set_xlabel('Recall')\n",
    "    ax.set_ylabel('Precision')\n",
    "    ax.set_title('Área bajo la curva Precision-Recall')\n",
    "    ax.legend()\n",
    "    \n",
    "def plot_AUC_ROC_PR(name, model, X_test, y_test):\n",
    "    y_model = model.predict(X_test)\n",
    "    roc_score = roc_auc_score(y_test, y_model)\n",
    "    ns_probs = [0 for _ in range(len(y_test))]\n",
    "    lr_probs = model.predict_proba(X_test)[:, 1]\n",
    "    ns_auc = roc_auc_score(y_test, ns_probs)\n",
    "    lr_auc = roc_auc_score(y_test, lr_probs)\n",
    "    ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n",
    "    lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
    "    lr_precision, lr_recall, _ = precision_recall_curve(y_test, lr_probs)\n",
    "    lr_f1, lr_auc = f1_score(y_test, y_model), auc(lr_recall, lr_precision)    \n",
    "    no_skill = len(y_test[y_test==1]) / len(y_test)\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n",
    "    ax[0].plot(ns_fpr, ns_tpr, linestyle='--')\n",
    "    ax[0].plot(lr_fpr, lr_tpr, marker='.', label=\"ROC curve (area = %0.2f)\" % roc_score)\n",
    "    ax[0].set_xlabel('Tasa de falsos positivos')\n",
    "    ax[0].set_ylabel('Tasa de verdaderos positivos')\n",
    "    ax[0].set_title('Área bajo la curva ROC')\n",
    "    ax[0].legend()\n",
    "    \n",
    "    ax[1].plot([0, 1], [no_skill, no_skill], linestyle='--')\n",
    "    ax[1].plot(lr_recall, lr_precision, marker='.', label=\"PR curve (area = %0.2f)\" % lr_auc)    \n",
    "    ax[1].set_xlabel('Recall')\n",
    "    ax[1].set_ylabel('Precision')\n",
    "    ax[1].set_title('Área bajo la curva Precision-Recall')\n",
    "    ax[1].legend()\n",
    "    fig.savefig('plots/'+name+'.png')\n",
    "    return roc_score, lr_auc    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "matched-panic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(386554, 16)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/Datos_listos_text_transfer_label.csv',\n",
    "                 dtype={'subject_id':object,\n",
    "                        'hadm_id':object,\n",
    "                        'stay_id':object,\n",
    "                        'stay_m':'uint16',\n",
    "                        'Admin_Hospi':'int8',\n",
    "                        'temperature':'float32',\n",
    "                        'heartrate':'float32',\n",
    "                        'resprate':'uint8',\n",
    "                        'o2sat':'float32',\n",
    "                        'sbp':'uint8',\n",
    "                        'dbp':'uint8',\n",
    "                        'pain':'float32',\n",
    "                        'gender':'int8',\n",
    "                        'Age':'uint8',\n",
    "                        'acuity':'uint8',\n",
    "                        'temperature_cat':'category',\n",
    "                        'heartrate_cat':'category', \n",
    "                        'resprate_cat':'category',\n",
    "                        'o2sat_cat':'category',\n",
    "                        'Presión arterial':'category',\n",
    "                        'Reingreso_24':'int8',\n",
    "                        'Reingreso_48':'int8',\n",
    "                        'Reingreso_72':'int8',\n",
    "                        'Reingresos_menores_72':'int8',\n",
    "                        'Hospitalization':'uint8',\n",
    "                        'ICU':'uint8',\n",
    "                        'Surgery':'uint8'},\n",
    "                                         #'acuity':'category'}#, \n",
    "                 parse_dates=['intime', 'outtime']\n",
    "                )\n",
    "df.set_index('stay_id', inplace=True)\n",
    "df.dropna(inplace=True) #1330\n",
    "df.shape #386554\n",
    "df['Destino'] = \"Ambulatorio\"\n",
    "df.loc[df['ICU']==1 , 'Destino'] = \"ICU\"\n",
    "df.loc[df['Hospitalization']==1 , 'Destino'] = \"Hospitalization\"\n",
    "df.loc[df['Surgery']==1 , 'Destino'] = \"Surgery\"\n",
    "df['Destino'] = df['Destino'].astype('category')\n",
    "df['Destino'] = df['Destino'].cat.codes\n",
    "df['Destino'].value_counts()\n",
    "df['temperature_dummy'] = 0\n",
    "df.loc[(df['temperature']<96.1)|(df['temperature']>99.2), 'temperature_dummy'] = 1\n",
    "df['heartrate_dummy'] = 0\n",
    "df.loc[(df['heartrate']<60)|(df['heartrate']>104), 'heartrate_dummy'] = 1\n",
    "df['resprate_dummy'] = 0\n",
    "df.loc[(df['resprate']<15)|(df['resprate']>19), 'resprate_dummy'] = 1\n",
    "df['o2sat_dummy'] = 0\n",
    "df.loc[(df['o2sat']<95), 'o2sat_dummy'] = 1\n",
    "df['Hora_in'] = df['intime'].dt.hour\n",
    "\n",
    "MM = MinMaxScaler()\n",
    "df[['temperature_MM', 'heartrate_MM',\n",
    "    'resprate_MM', 'o2sat_MM',\n",
    "    'sbp_MM', 'dbp_MM',\n",
    "    'pain_MM', 'Age_MM']] = MM.fit_transform(df[['temperature', 'heartrate',\n",
    "                                                 'resprate', 'o2sat',\n",
    "                                                 'sbp', 'dbp',\n",
    "                                                 'pain', 'Age']])\n",
    "\n",
    "X = pd.merge(df[['temperature_MM', 'heartrate_MM',\n",
    "                   'resprate_MM', 'o2sat_MM',\n",
    "                   'sbp_MM', 'dbp_MM',\n",
    "                   'pain_MM', 'Age_MM',\n",
    "                   'gender', 'Reingresos_menores_72', #'Hora_in',\n",
    "                   'temperature_dummy', 'heartrate_dummy', 'resprate_dummy', 'o2sat_dummy']],\n",
    "               pd.get_dummies(df['Presión arterial']).drop(columns=['Normal']),\n",
    "               left_index=True, right_index=True)\n",
    "X['anomalos'] = X[['temperature_dummy', 'heartrate_dummy',\n",
    "                   'resprate_dummy', 'o2sat_dummy', 'Baja',\n",
    "                   'Elevada', 'Estadio 1', 'Estadio 2']].sum(axis=1)\n",
    "X['presure_dummy'] = X[['Baja','Elevada', 'Estadio 1', 'Estadio 2']].sum(axis=1)\n",
    "X.drop(columns=['Baja','Elevada', 'Estadio 1', 'Estadio 2'], inplace=True)\n",
    "X.shape    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ef972df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.58 s\n",
      "Wall time: 2.63 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(386554, 200)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "tfidf = TfidfVectorizer(encoding='utf-8',\n",
    "                        ngram_range=(1,1),\n",
    "                        stop_words=None,\n",
    "                        lowercase=False,\n",
    "                        max_df=1.,\n",
    "                        min_df=10,\n",
    "                        max_features=200,\n",
    "                        norm='l2',\n",
    "                        sublinear_tf=True)\n",
    "# se aplica el TFIDF\n",
    "features = tfidf.fit_transform(df['chiefcomplaint']).toarray()\n",
    "X = pd.DataFrame(features, index= df.index, columns=tfidf.get_feature_names())\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08822145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(386554, 216)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_0 = pd.merge(df[['temperature_MM', 'heartrate_MM',\n",
    "                   'resprate_MM', 'o2sat_MM',\n",
    "                   'sbp_MM', 'dbp_MM',\n",
    "                   'pain_MM', 'Age_MM',\n",
    "                   'gender', 'Reingresos_menores_72', #'Hora_in',\n",
    "                   'temperature_dummy', 'heartrate_dummy', 'resprate_dummy', 'o2sat_dummy']],\n",
    "               pd.get_dummies(df['Presión arterial']).drop(columns=['Normal']),\n",
    "               left_index=True, right_index=True)\n",
    "X_0['anomalos'] = X_0[['temperature_dummy', 'heartrate_dummy',\n",
    "                   'resprate_dummy', 'o2sat_dummy', 'Baja',\n",
    "                   'Elevada', 'Estadio 1', 'Estadio 2']].sum(axis=1)\n",
    "X_0['presure_dummy'] = X_0[['Baja','Elevada', 'Estadio 1', 'Estadio 2']].sum(axis=1)\n",
    "X_0.drop(columns=['Baja','Elevada', 'Estadio 1', 'Estadio 2'], inplace=True)\n",
    "\n",
    "X = pd.merge(X_0, pd.DataFrame(features, index= df.index, columns=tfidf.get_feature_names()),\n",
    "             left_index=True, right_index=True)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9a2725e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(386554, 217)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['acuity'] = df['acuity'].astype('category')\n",
    "X_0 = pd.merge(df[['acuity', \n",
    "                   'temperature_MM', 'heartrate_MM',\n",
    "                   'resprate_MM', 'o2sat_MM',\n",
    "                   'sbp_MM', 'dbp_MM',\n",
    "                   'pain_MM', 'Age_MM',\n",
    "                   'gender', 'Reingresos_menores_72', #'Hora_in',\n",
    "                   'temperature_dummy', 'heartrate_dummy', 'resprate_dummy', 'o2sat_dummy']],\n",
    "               pd.get_dummies(df['Presión arterial']).drop(columns=['Normal']),\n",
    "               left_index=True, right_index=True)\n",
    "X_0['anomalos'] = X_0[['temperature_dummy', 'heartrate_dummy',\n",
    "                   'resprate_dummy', 'o2sat_dummy', 'Baja',\n",
    "                   'Elevada', 'Estadio 1', 'Estadio 2']].sum(axis=1)\n",
    "X_0['presure_dummy'] = X_0[['Baja','Elevada', 'Estadio 1', 'Estadio 2']].sum(axis=1)\n",
    "X_0.drop(columns=['Baja','Elevada', 'Estadio 1', 'Estadio 2'], inplace=True)\n",
    "\n",
    "X = pd.merge(X_0, pd.DataFrame(features, index= df.index, columns=tfidf.get_feature_names()),\n",
    "             left_index=True, right_index=True)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0420b1ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICU\n",
      "Surgery\n",
      "Hospitalization\n",
      "Admin_Hospi\n"
     ]
    }
   ],
   "source": [
    "ys = ['ICU', 'Surgery', 'Hospitalization', 'Admin_Hospi']\n",
    "casos = ['0', '2', '3']\n",
    "for j in ys:\n",
    "    print(j)\n",
    "    y = df[j]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    #if j == 'Admin_Hospi': j = 'Admin'\n",
    "    for i in casos:\n",
    "        LGBM = joblib.load('models/LR_Numericas_text_numbers_acuity_'+j+i+'.joblib')\n",
    "        y_pred = pd.Series(LGBM.predict_proba(X_test)[:, 1], index=X_test.index)\n",
    "        y_model = LGBM.predict(X_test)\n",
    "        roc = roc_auc_score(y_test, y_pred)\n",
    "        t1 = Interval(y_test, y_pred, alpha = 5.0)\n",
    "        record = pd.read_excel('outputs/Tabla_Resultados.xlsx', engine='openpyxl')\n",
    "        run = {'Fecha_hora':pd.to_datetime('today'),\n",
    "               'Tamaño_test': X_test.shape, #i,\n",
    "               'Dependiente':j,\n",
    "               'Modelo': 'LogisticRegression_text_numbers_acuity_'+j+i,#u,\n",
    "               'Parametros': 'NA',#LGBM.params_,\n",
    "               'ROC_AUC_train': 'NA',#LGBM.score_,\n",
    "               'ROC_AUC_Score': roc,\n",
    "               'Intervalo_ROC_AUC':t1, \n",
    "               'PR_AUC_Score': 0,\n",
    "               'Intervalo_PR_AUC': 0,\n",
    "               'f1_score': f1_score(y_test, y_model), \n",
    "               'Accuracy': accuracy_score(y_test, y_model),\n",
    "               'balanced_accuracy': balanced_accuracy_score(y_test, y_model),\n",
    "               'vars':', '.join(X_train.columns)\n",
    "              }\n",
    "        record = record.append(run, ignore_index=True)\n",
    "        record.to_excel('outputs/Tabla_Resultados.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preceding-element",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(121202, 217)\n",
      "(51945, 217)\n",
      "(0.50, 0.50) (0.54, 0.54)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ys = [ 'Surgery', 'ICU']#ICU\n",
    "for j in ys:\n",
    "    y = df[df['Admin_Hospi']==1][j]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    print(X_train.shape)\n",
    "    print(X_test.shape)\n",
    "    for i in range(4):\n",
    "        try:\n",
    "            model = BayesSearchCV(LogisticRegression(),\n",
    "                                  espacio[i],\n",
    "                                  scoring='roc_auc',\n",
    "                                  n_points= 5,\n",
    "                                  n_iter= 50,\n",
    "                                  cv= 5,\n",
    "                                  verbose = 0,\n",
    "                                  n_jobs=6,\n",
    "                                  random_state= 88)\n",
    "            model.fit(X_train, y_train)\n",
    "            clf = model.best_estimator_\n",
    "            y_model = pd.Series(clf.predict(X_test), index=X_test.index)\n",
    "            roc, pr = plot_AUC_ROC_PR('LogisticRegression_text_numbers_acuity_ofAdmin_'+j+str(i), clf, X_test, y_test)\n",
    "            t1, t2 = Interval(y_test, y_model, alpha = 5.0)\n",
    "            print(t1, t2)\n",
    "            record = pd.read_excel('outputs/Tabla_Resultados.xlsx', engine='openpyxl')\n",
    "            run = {'Fecha_hora':pd.to_datetime('today'),\n",
    "                   'Tamaño_test': X_test.shape, #i,\n",
    "                   'Dependiente':j,\n",
    "                   'Modelo': 'LogisticRegression_text_numbers_acuity_ofAdmin'+str(i),#u,\n",
    "                   'Parametros': model.best_params_,\n",
    "                   'ROC_AUC_train': model.best_score_,\n",
    "                   'ROC_AUC_Score': roc,\n",
    "                   'Intervalo_ROC_AUC':t1, \n",
    "                   'PR_AUC_Score': pr,\n",
    "                   'Intervalo_PR_AUC':t2,\n",
    "                   'f1_score': f1_score(y_test, y_model), \n",
    "                   'Accuracy': accuracy_score(y_test, y_model),\n",
    "                   'balanced_accuracy': balanced_accuracy_score(y_test, y_model),\n",
    "                   'vars':', '.join(X_train.columns)\n",
    "                  }\n",
    "            joblib.dump(clf, 'models/LR_Numericas_text_numbers_acuity_ofAdmin_'+j+str(i)+'.joblib')\n",
    "            record = record.append(run, ignore_index=True)\n",
    "            record.to_excel('outputs/Tabla_Resultados.xlsx', index=False)\n",
    "            plot_confusion_matrix(clf, X_test, y_test, normalize='true')\n",
    "        except:\n",
    "            print('se presentó un error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "illegal-flash",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "y = df['Destino']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "model = BayesSearchCV(LGBMClassifier(),\n",
    "                      espacio,\n",
    "                      scoring='accuracy',\n",
    "                      n_points= 5,\n",
    "                      n_iter= 50,\n",
    "                      cv= 5,\n",
    "                      verbose = 0,\n",
    "                      n_jobs=6,\n",
    "                      random_state= 88)\n",
    "model.fit(X_train, y_train)\n",
    "clf = model.best_estimator_\n",
    "y_model = pd.Series(clf.predict(X_test), index=X_test.index)\n",
    "roc, pr = plot_AUC_ROC_PR('LGBMClassifier_Destino_text_numbers_acuity', clf, X_test, y_test)\n",
    "t1, t2 = Interval(y_test, y_model, alpha = 5.0)\n",
    "print(t1, t2)\n",
    "record = pd.read_excel('outputs/Tabla_Resultados.xlsx', engine='openpyxl')\n",
    "run = {'Fecha_hora':pd.to_datetime('today'),\n",
    "       'Tamaño_test': X_test.shape, #i,\n",
    "       'Dependiente':'Destino',\n",
    "       'Modelo': 'LGBMClassifier_text_numbers_acuity',#u,\n",
    "       'Parametros': model.best_params_,\n",
    "       'ROC_AUC_train': model.best_score_,\n",
    "       'ROC_AUC_Score': roc,\n",
    "       'Intervalo_ROC_AUC':t1, \n",
    "       'PR_AUC_Score': pr,\n",
    "       'Intervalo_PR_AUC':t2,\n",
    "       'f1_score': f1_score(y_test, y_model), \n",
    "       'Accuracy': accuracy_score(y_test, y_model),\n",
    "       'balanced_accuracy': balanced_accuracy_score(y_test, y_model),\n",
    "       'vars':', '.join(X_train.columns)\n",
    "      }\n",
    "joblib.dump(clf, 'models/LGBM_text_numbers_acuity_Destino.joblib')\n",
    "record = record.append(run, ignore_index=True)\n",
    "record.to_excel('outputs/Tabla_Resultados.xlsx', index=False)\n",
    "plot_confusion_matrix(clf, X_test, y_test, normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "victorian-eating",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_class = 'ovr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-trance",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y = df['Destino']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "model = BayesSearchCV(LGBMClassifier(),\n",
    "                      espacio,\n",
    "                      scoring='balanced_accuracy',\n",
    "                      n_points= 5,\n",
    "                      n_iter= 50,\n",
    "                      cv= 5,\n",
    "                      verbose = 0,\n",
    "                      n_jobs=6,\n",
    "                      random_state= 88)\n",
    "model.fit(X_train, y_train)\n",
    "clf = model.best_estimator_\n",
    "y_model = pd.Series(clf.predict(X_test), index=X_test.index)\n",
    "roc, pr = plot_AUC_ROC_PR('LGBMClassifier_Destino_text_numbers_acuity', clf, X_test, y_test)\n",
    "t1, t2 = Interval(y_test, y_model, alpha = 5.0)\n",
    "print(t1, t2)\n",
    "record = pd.read_excel('outputs/Tabla_Resultados.xlsx', engine='openpyxl')\n",
    "run = {'Fecha_hora':pd.to_datetime('today'),\n",
    "       'Tamaño_test': X_test.shape, #i,\n",
    "       'Dependiente':'Destino',\n",
    "       'Modelo': 'LGBMClassifier_text_numbers_acuity',#u,\n",
    "       'Parametros': model.best_params_,\n",
    "       'ROC_AUC_train': model.best_score_,\n",
    "       'ROC_AUC_Score': roc,\n",
    "       'Intervalo_ROC_AUC':t1, \n",
    "       'PR_AUC_Score': pr,\n",
    "       'Intervalo_PR_AUC':t2,\n",
    "       'f1_score': f1_score(y_test, y_model), \n",
    "       'Accuracy': accuracy_score(y_test, y_model),\n",
    "       'balanced_accuracy': balanced_accuracy_score(y_test, y_model),\n",
    "       'vars':', '.join(X_train.columns)\n",
    "      }\n",
    "joblib.dump(clf, 'models/LGBM_text_numbers_acuity_Destino.joblib')\n",
    "record = record.append(run, ignore_index=True)\n",
    "record.to_excel('outputs/Tabla_Resultados.xlsx', index=False)\n",
    "plot_confusion_matrix(clf, X_test, y_test, normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "periodic-carter",
   "metadata": {},
   "outputs": [],
   "source": [
    "espacio = {\"n_estimators\": Integer(10, 3000),\n",
    "           'max_depth':Integer(1, 40),\n",
    "           'num_leaves': Integer(2, 500),\n",
    "           'learning_rate': Real(0.0001, 0.3, prior='uniform'),\n",
    "           'lambda_l1': Real(1e-8, 10.0, prior='log-uniform'),\n",
    "           'lambda_l2': Real(1e-8, 10.0, prior='log-uniform'),\n",
    "           'num_leaves': Integer(2, 256),\n",
    "           'feature_fraction': Real(0.4, 1.0, prior='uniform'),\n",
    "           'bagging_fraction': Real(0.4, 1.0, prior='uniform'),\n",
    "           'bagging_freq': Integer(1, 7),\n",
    "           'min_child_samples': Integer(5, 100),\n",
    "           'subsample':Real(0.2, 1, prior='uniform')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gothic-technology",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "import lightgbm as lgb\n",
    "y = df['Admin_Hospi']\n",
    "def objective(trial):\n",
    "    #data, target = sklearn.datasets.load_breast_cancer(return_X_y=True)\n",
    "    train_x, test_x, train_y, test_y = train_test_split(X, y, test_size=0.25)\n",
    "    dtrain = lgb.Dataset(train_x, label=train_y)\n",
    " \n",
    "    param = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        \"n_estimators\": trial.suggest_int('n_estimators', 10, 3000),\n",
    "        'max_depth':trial.suggest_int('max_depth', 1, 40),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-10, 1),\n",
    "        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n",
    "        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n",
    "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "    }\n",
    " \n",
    "    gbm = lgb.train(param, dtrain)\n",
    "    preds = gbm.predict(test_x)\n",
    "    pred_labels = np.rint(preds)\n",
    "    roc_auc = roc_auc_score(test_y, pred_labels)\n",
    "    return roc_auc\n",
    " \n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decent-happening",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:', study.best_trial.params)\n",
    "print('Best score:', study.best_trial.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shared-brighton",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna.integration.lightgbm as lgb\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size=0.25)\n",
    "dtrain = lgb.Dataset(train_x, label=train_y)\n",
    "dval = lgb.Dataset(test_x, label=test_y)\n",
    "\n",
    "params = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"binary_logloss\",\n",
    "    } \n",
    "\n",
    "best_params, tuning_history = dict(), list()\n",
    "booster = lgb.train(params, dtrain, valid_sets=dval,\n",
    "                    verbose_eval=0,\n",
    "                    best_params=best_params,\n",
    "                    tuning_history=tuning_history)\n",
    " \n",
    "print('Best Params:', best_params)\n",
    "print('Tuning history:', tuning_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "individual-courtesy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_run() -> None:\n",
    "    params = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"binary_logloss\",\n",
    "    }  # type: Dict\n",
    "    dtrain = lgb.Dataset(train_x, label=train_y)\n",
    "    dval = lgb.Dataset(test_x, label=test_y)\n",
    "\n",
    "    study = optuna.create_study()\n",
    "    tuner = lgb.LightGBMTuner(params,\n",
    "                              dtrain,\n",
    "                              study=study,\n",
    "                              valid_sets=dval,\n",
    "                              verbose_eval=1,\n",
    "                              early_stopping_rounds=1,\n",
    "                              num_boost_round=2)\n",
    "    tuner.run()\n",
    "    df_trials = study.trials_dataframe()\n",
    "    assert len(df_trials) == 68\n",
    "    assert len(df_trials[df_trials[\"state\"] == \"COMPLETE\"]) == 68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinate-sweden",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_params =  {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': 7,\n",
    "    'metric': ['multi_error'],\n",
    "    \"learning_rate\": 0.05,\n",
    "     \"num_leaves\": 60,\n",
    "     \"max_depth\": 9,\n",
    "     \"feature_fraction\": 0.45,\n",
    "     \"bagging_fraction\": 0.3,\n",
    "     \"reg_alpha\": 0.15,\n",
    "     \"reg_lambda\": 0.15,\n",
    "#      \"min_split_gain\": 0,\n",
    "      \"min_child_weight\": 0\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabulous-cleaning",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelstart= time.time()\n",
    "# Find Optimal Parameters / Boosting Rounds\n",
    "lgb_cv = lgb.cv(\n",
    "    params = lgbm_params,\n",
    "    train_set = lgtrain,\n",
    "    num_boost_round=2000,\n",
    "    stratified=True,\n",
    "    nfold = 5,\n",
    "    verbose_eval=50,\n",
    "    seed = 23,\n",
    "    early_stopping_rounds=75)\n",
    "\n",
    "loss = lgbm_params[\"metric\"][0]\n",
    "optimal_rounds = np.argmin(lgb_cv[str(loss) + '-mean'])\n",
    "best_cv_score = min(lgb_cv[str(loss) + '-mean'])\n",
    "\n",
    "print(\"\\nOptimal Round: {}\\nOptimal Score: {} + {}\".format(\n",
    "    optimal_rounds,best_cv_score,lgb_cv[str(loss) + '-stdv'][optimal_rounds]))\n",
    "\n",
    "results = results.append({\"Rounds\": optimal_rounds,\n",
    "                          \"Score\": best_cv_score,\n",
    "                          \"STDV\": lgb_cv[str(loss) + '-stdv'][optimal_rounds],\n",
    "                          \"LB\": None,\n",
    "                          \"Parameters\": lgbm_params}, ignore_index=True)\n",
    "if Home is True:\n",
    "    with open('results.csv', 'a') as f:\n",
    "        results.to_csv(f, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secret-trademark",
   "metadata": {},
   "outputs": [],
   "source": [
    "espacio = {\"n_estimators\": (1, 3000),\n",
    "           'min_samples_split': (2,50),\n",
    "           'min_samples_leaf': (1,50),\n",
    "           'max_depth':(1, 20),\n",
    "           'class_weight': [\"balanced\", \"balanced_subsample\"],\n",
    "           \"bootstrap\": [True, False],\n",
    "           \"criterion\": [\"gini\", \"entropy\"],}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virgin-security",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Admin_Hospi']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "model = BayesSearchCV(RandomForestClassifier(),\n",
    "                      espacio,\n",
    "                      scoring='roc_auc',\n",
    "                      n_points= 5,\n",
    "                      n_iter= 50,\n",
    "                      cv= 5,\n",
    "                      verbose = 3,\n",
    "                      n_jobs=6,\n",
    "                      random_state= 88)\n",
    "model.fit(X_train, y_train)\n",
    "clf = model.best_estimator_\n",
    "y_model = pd.Series(clf.predict(X_test), index=X_test.index)\n",
    "roc, pr = plot_AUC_ROC_PR('LGBMClassifier_V5_'+'Admin_Hospi', clf, X_test, y_test)\n",
    "t1, t2 = Interval(y_test, y_model, alpha = 5.0)\n",
    "print(t1, t2)\n",
    "record = pd.read_excel('outputs/Tabla_Resultados.xlsx', engine='openpyxl')\n",
    "run = {'Fecha_hora':pd.to_datetime('today'),\n",
    "       'Tamaño_test': X_test.shape, #i,\n",
    "       'Dependiente':'Admin_Hospi',\n",
    "       'Modelo': 'RandomForestClassifier_MM',#u,\n",
    "       'Parametros': model.best_params_,\n",
    "       'ROC_AUC_train': model.best_score_,\n",
    "       'ROC_AUC_Score': roc,\n",
    "       'Intervalo_ROC_AUC':t1, \n",
    "       'PR_AUC_Score': pr,\n",
    "       'Intervalo_PR_AUC':t2,\n",
    "       'f1_score': f1_score(y_test, y_model), \n",
    "       'Accuracy': accuracy_score(y_test, y_model),\n",
    "       'balanced_accuracy': balanced_accuracy_score(y_test, y_model),\n",
    "       'vars':', '.join(X_train.columns)\n",
    "      }\n",
    "record = record.append(run, ignore_index=True)\n",
    "record.to_excel('outputs/Tabla_Resultados.xlsx', index=False)\n",
    "joblib.dump(clf, 'models/RF_Numericas_dummy.joblib')\n",
    "plot_confusion_matrix(clf, X_test, y_test, normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pretty-strike",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(clf)\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "shap.summary_plot(shap_values[1], X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norman-thong",
   "metadata": {},
   "outputs": [],
   "source": [
    "espacio = {'solver': ['liblinear', 'saga'],  \n",
    "           'penalty': ['l1','l2'],\n",
    "           'tol': (1e-5, 1e-3, 'log-uniform'),\n",
    "           'C': (1e-5, 100, 'log-uniform'),\n",
    "           'fit_intercept': [True, False]}\n",
    "y = df['Admin_Hospi']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powered-haiti",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BayesSearchCV(LogisticRegression(),\n",
    "                      espacio,\n",
    "                      scoring='roc_auc',\n",
    "                      n_points= 5,\n",
    "                      n_iter= 50,\n",
    "                      cv= 5,\n",
    "                      verbose = 0,\n",
    "                      n_jobs=6,\n",
    "                      random_state= 88)\n",
    "model.fit(X_train, y_train)\n",
    "clf = model.best_estimator_\n",
    "y_model = pd.Series(clf.predict(X_test), index=X_test.index)\n",
    "roc, pr = plot_AUC_ROC_PR('LGBMClassifier_V5_'+'Admin_Hospi', clf, X_test, y_test)\n",
    "t1, t2 = Interval(y_test, y_model, alpha = 5.0)\n",
    "print(t1, t2)\n",
    "record = pd.read_excel('outputs/Tabla_Resultados.xlsx', engine='openpyxl')\n",
    "run = {'Fecha_hora':pd.to_datetime('today'),\n",
    "       'Tamaño_test': X_test.shape, #i,\n",
    "       'Dependiente':'Admin_Hospi',\n",
    "       'Modelo': 'LogisticRegression_MM',#u,\n",
    "       'Parametros': model.best_params_,\n",
    "       'ROC_AUC_train': model.best_score_,\n",
    "       'ROC_AUC_Score': roc,\n",
    "       'Intervalo_ROC_AUC':t1, \n",
    "       'PR_AUC_Score': pr,\n",
    "       'Intervalo_PR_AUC':t2,\n",
    "       'f1_score': f1_score(y_test, y_model), \n",
    "       'Accuracy': accuracy_score(y_test, y_model),\n",
    "       'balanced_accuracy': balanced_accuracy_score(y_test, y_model),\n",
    "       'vars':', '.join(X_train.columns)\n",
    "      }\n",
    "record = record.append(run, ignore_index=True)\n",
    "record.to_excel('outputs/Tabla_Resultados.xlsx', index=False)\n",
    "joblib.dump(clf, 'models/LR_Numericas_dummy.joblib')\n",
    "plot_confusion_matrix(clf, X_test, y_test, normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statewide-graph",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('intercept ', clf.intercept_[0])\n",
    "print('classes', clf.classes_)\n",
    "pd.DataFrame({'coeff': clf.coef_[0]}, \n",
    "             index=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "natural-pharmacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "espacio = {'var_smoothing': Real(1e-9, 1, prior='log-uniform')}\n",
    "\n",
    "model = BayesSearchCV(GaussianNB(),\n",
    "                      espacio,\n",
    "                      scoring='roc_auc',\n",
    "                      #n_points= 5,\n",
    "                      n_iter= 50,\n",
    "                      cv= 5,\n",
    "                      verbose = 0,\n",
    "                      n_jobs=6,\n",
    "                      random_state= 88)\n",
    "model.fit(X_train, y_train)\n",
    "clf = model.best_estimator_\n",
    "y_model = pd.Series(clf.predict(X_test), index=X_test.index)\n",
    "roc, pr = plot_AUC_ROC_PR('GaussianNB_V5_'+'Admin_Hospi', clf, X_test, y_test)\n",
    "t1, t2 = Interval(y_test, y_model, alpha = 5.0)\n",
    "print(t1, t2)\n",
    "record = pd.read_excel('outputs/Tabla_Resultados.xlsx', engine='openpyxl')\n",
    "run = {'Fecha_hora':pd.to_datetime('today'),\n",
    "       'Tamaño_test': X_test.shape, #i,\n",
    "       'Dependiente':'Admin_Hospi',\n",
    "       'Modelo': 'GaussianNB_MM',#u,\n",
    "       'Parametros': model.best_params_,\n",
    "       'ROC_AUC_train': model.best_score_,\n",
    "       'ROC_AUC_Score': roc,\n",
    "       'Intervalo_ROC_AUC':t1, \n",
    "       'PR_AUC_Score': pr,\n",
    "       'Intervalo_PR_AUC':t2,\n",
    "       'f1_score': f1_score(y_test, y_model), \n",
    "       'Accuracy': accuracy_score(y_test, y_model),\n",
    "       'balanced_accuracy': balanced_accuracy_score(y_test, y_model),\n",
    "       'vars':', '.join(X_train.columns)\n",
    "      }\n",
    "record = record.append(run, ignore_index=True)\n",
    "record.to_excel('outputs/Tabla_Resultados.xlsx', index=False)\n",
    "joblib.dump(clf, 'models/NB_Numericas_dummy.joblib')\n",
    "plot_confusion_matrix(clf, X_test, y_test, normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affected-breast",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medieval-noise",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['temperature_dummy'] = 0\n",
    "df.loc[(df['temperature']<96.1)|(df['temperature']>99.2), 'temperature_dummy'] = 1\n",
    "df['heartrate_dummy'] = 0\n",
    "df.loc[(df['heartrate']<60)|(df['heartrate']>104), 'heartrate_dummy'] = 1\n",
    "df['resprate_dummy'] = 0\n",
    "df.loc[(df['resprate']<15)|(df['resprate']>19), 'resprate_dummy'] = 1\n",
    "df['o2sat_dummy'] = 0\n",
    "df.loc[(df['o2sat']<95), 'o2sat_dummy'] = 1\n",
    "df['Hora_in'] = df['intime'].dt.hour\n",
    "\n",
    "MM = MinMaxScaler()\n",
    "df[['temperature_MM', 'heartrate_MM',\n",
    "    'resprate_MM', 'o2sat_MM',\n",
    "    'sbp_MM', 'dbp_MM',\n",
    "    'pain_MM', 'Age_MM']] = MM.fit_transform(df[['temperature', 'heartrate',\n",
    "                                                 'resprate', 'o2sat',\n",
    "                                                 'sbp', 'dbp',\n",
    "                                                 'pain', 'Age']])\n",
    "\n",
    "X_0 = pd.merge(df[['temperature_MM', 'heartrate_MM',\n",
    "                   'resprate_MM', 'o2sat_MM',\n",
    "                   'sbp_MM', 'dbp_MM',\n",
    "                   'pain_MM', 'Age_MM',\n",
    "                   'gender', 'Reingresos_menores_72', #'Hora_in',\n",
    "                   'temperature_dummy', 'heartrate_dummy', 'resprate_dummy', 'o2sat_dummy']],\n",
    "               pd.get_dummies(df['Presión arterial']).drop(columns=['Normal']),\n",
    "               left_index=True, right_index=True)\n",
    "X = pd.merge(X_0, pd.DataFrame(features, index= df.index, columns=tfidf.get_feature_names()),\n",
    "             left_index=True, right_index=True)\n",
    "X['anomalos'] = X[['temperature_dummy', 'heartrate_dummy',\n",
    "                   'resprate_dummy', 'o2sat_dummy', 'Baja',\n",
    "                   'Elevada', 'Estadio 1', 'Estadio 2']].sum(axis=1)\n",
    "X.shape  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handled-senegal",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ICU_QX'] = df['ICU'] + df['Surgery']\n",
    "df['ICU_QX'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breeding-luxembourg",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y = df['ICU_QX']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "model = BayesSearchCV(LGBMClassifier(),\n",
    "                      espacio,\n",
    "                      scoring='roc_auc',\n",
    "                      n_points= 5,\n",
    "                      n_iter= 50,\n",
    "                      cv= 5,\n",
    "                      verbose = 0,\n",
    "                      n_jobs=6,\n",
    "                      random_state= 88)\n",
    "model.fit(X_train, y_train)\n",
    "clf = model.best_estimator_\n",
    "y_model = pd.Series(clf.predict(X_test), index=X_test.index)\n",
    "roc, pr = plot_AUC_ROC_PR('LGBMClassifier_V5_'+'Admin_Hospi', clf, X_test, y_test)\n",
    "t1, t2 = Interval(y_test, y_model, alpha = 5.0)\n",
    "print(t1, t2)\n",
    "record = pd.read_excel('outputs/Tabla_Resultados.xlsx', engine='openpyxl')\n",
    "run = {'Fecha_hora':pd.to_datetime('today'),\n",
    "       'Tamaño_test': X_test.shape, #i,\n",
    "       'Dependiente':'Admin_Hospi', # ------------------------------------CAMBIAR NOMBRE\n",
    "       'Modelo': 'LGBMClassifier_V6_MM',#u,\n",
    "       'Parametros': model.best_params_,\n",
    "       'ROC_AUC_train': model.best_score_,\n",
    "       'ROC_AUC_Score': roc,\n",
    "       'Intervalo_ROC_AUC':t1, \n",
    "       'PR_AUC_Score': pr,\n",
    "       'Intervalo_PR_AUC':t2,\n",
    "       'f1_score': f1_score(y_test, y_model), \n",
    "       'Accuracy': accuracy_score(y_test, y_model),\n",
    "       'balanced_accuracy': balanced_accuracy_score(y_test, y_model),\n",
    "      }\n",
    "record = record.append(run, ignore_index=True)\n",
    "record.to_excel('outputs/Tabla_Resultados.xlsx', index=False)\n",
    "plot_confusion_matrix(clf, X_test, y_test, normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "computational-joseph",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y = df['ICU_QX']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_resampled, y_resampled = ADASYN().fit_resample(X_train, y_train)\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(X_train.shape, X_resampled.shape)\n",
    "\n",
    "model = BayesSearchCV(LGBMClassifier(),\n",
    "                      espacio,\n",
    "                      scoring='roc_auc',\n",
    "                      n_points= 5,\n",
    "                      n_iter= 50,\n",
    "                      cv= 5,\n",
    "                      verbose = 0,\n",
    "                      n_jobs=6,\n",
    "                      random_state= 88)\n",
    "model.fit(X_resampled, y_resampled)\n",
    "clf = model.best_estimator_\n",
    "y_model = pd.Series(clf.predict(X_test), index=X_test.index)\n",
    "roc, pr = plot_AUC_ROC_PR('LGBMClassifier_V5_'+'Admin_Hospi', clf, X_test, y_test)\n",
    "t1, t2 = Interval(y_test, y_model, alpha = 5.0)\n",
    "print(t1, t2)\n",
    "record = pd.read_excel('outputs/Tabla_Resultados.xlsx', engine='openpyxl')\n",
    "run = {'Fecha_hora':pd.to_datetime('today'),\n",
    "       'Tamaño_test': X_test.shape, #i,\n",
    "       'Dependiente':'Admin_Hospi', # ------------------------------------CAMBIAR NOMBRE\n",
    "       'Modelo': 'LGBMClassifier_V6_MM_ADASYN',#u,\n",
    "       'Parametros': model.best_params_,\n",
    "       'ROC_AUC_train': model.best_score_,\n",
    "       'ROC_AUC_Score': roc,\n",
    "       'Intervalo_ROC_AUC':t1, \n",
    "       'PR_AUC_Score': pr,\n",
    "       'Intervalo_PR_AUC':t2,\n",
    "       'f1_score': f1_score(y_test, y_model), \n",
    "       'Accuracy': accuracy_score(y_test, y_model),\n",
    "       'balanced_accuracy': balanced_accuracy_score(y_test, y_model),\n",
    "      }\n",
    "record = record.append(run, ignore_index=True)\n",
    "record.to_excel('outputs/Tabla_Resultados.xlsx', index=False)\n",
    "plot_confusion_matrix(clf, X_test, y_test, normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rocky-nerve",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df[df['Admin_Hospi']==1]\n",
    "df_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-suspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2['ICU_QX'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compatible-dealer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(encoding='utf-8',\n",
    "                        ngram_range=(1,1),\n",
    "                        stop_words=None,\n",
    "                        lowercase=False,\n",
    "                        max_df=1.,\n",
    "                        min_df=10,\n",
    "                        max_features=200,\n",
    "                        norm='l2',\n",
    "                        sublinear_tf=True)\n",
    "# se aplica el TFIDF\n",
    "features = tfidf.fit_transform(df_2['chiefcomplaint']).toarray()\n",
    "features.shape\n",
    "\n",
    "X_0 = pd.merge(df_2[['temperature_MM', 'heartrate_MM',\n",
    "                     'resprate_MM', 'o2sat_MM',\n",
    "                     'sbp_MM', 'dbp_MM',\n",
    "                     'pain_MM', 'Age_MM',\n",
    "                     'gender', 'Reingresos_menores_72', #'Hora_in',\n",
    "                     'temperature_dummy', 'heartrate_dummy', 'resprate_dummy', 'o2sat_dummy']],\n",
    "               pd.get_dummies(df['Presión arterial']).drop(columns=['Normal']),\n",
    "               left_index=True, right_index=True)\n",
    "X = pd.merge(X_0, pd.DataFrame(features, index= df_2.index, columns=tfidf.get_feature_names()),\n",
    "             left_index=True, right_index=True)\n",
    "X['anomalos'] = X[['temperature_dummy', 'heartrate_dummy', 'resprate_dummy',\n",
    "                   'o2sat_dummy', 'Baja', 'Elevada', 'Estadio 1', 'Estadio 2']].sum(axis=1)\n",
    "X.shape  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boring-steering",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y = df_2['ICU_QX']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "model = BayesSearchCV(LGBMClassifier(),\n",
    "                      espacio,\n",
    "                      scoring='roc_auc',\n",
    "                      n_points= 5,\n",
    "                      n_iter= 50,\n",
    "                      cv= 5,\n",
    "                      verbose = 0,\n",
    "                      n_jobs=6,\n",
    "                      random_state= 88)\n",
    "model.fit(X_train, y_train)\n",
    "clf = model.best_estimator_\n",
    "y_model = pd.Series(clf.predict(X_test), index=X_test.index)\n",
    "roc, pr = plot_AUC_ROC_PR('LGBMClassifier_V5_'+'Admin_Hospi', clf, X_test, y_test)\n",
    "t1, t2 = Interval(y_test, y_model, alpha = 5.0)\n",
    "print(t1, t2)\n",
    "record = pd.read_excel('outputs/Tabla_Resultados.xlsx', engine='openpyxl')\n",
    "run = {'Fecha_hora':pd.to_datetime('today'),\n",
    "       'Tamaño_test': X_test.shape, #i,\n",
    "       'Dependiente':'ICU_QX',\n",
    "       'Modelo': 'LGBMClassifier_V6_BA',#u,\n",
    "       'Parametros': model.best_params_,\n",
    "       'ROC_AUC_train': model.best_score_,\n",
    "       'ROC_AUC_Score': roc,\n",
    "       'Intervalo_ROC_AUC':t1, \n",
    "       'PR_AUC_Score': pr,\n",
    "       'Intervalo_PR_AUC':t2,\n",
    "       'f1_score': f1_score(y_test, y_model), \n",
    "       'Accuracy': accuracy_score(y_test, y_model),\n",
    "       'balanced_accuracy': balanced_accuracy_score(y_test, y_model),\n",
    "      }\n",
    "record = record.append(run, ignore_index=True)\n",
    "record.to_excel('outputs/Tabla_Resultados.xlsx', index=False)\n",
    "plot_confusion_matrix(clf, X_test, y_test, normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jewish-winter",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y = df_2['ICU_QX']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_resampled, y_resampled = RandomOverSampler().fit_resample(X_train, y_train)\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(X_train.shape, X_resampled.shape)\n",
    "\n",
    "model = BayesSearchCV(LGBMClassifier(),\n",
    "                      espacio,\n",
    "                      scoring='roc_auc',\n",
    "                      n_points= 5,\n",
    "                      n_iter= 50,\n",
    "                      cv= 5,\n",
    "                      verbose = 0,\n",
    "                      n_jobs=6,\n",
    "                      random_state= 88)\n",
    "model.fit(X_resampled, y_resampled)\n",
    "clf = model.best_estimator_\n",
    "y_model = pd.Series(clf.predict(X_test), index=X_test.index)\n",
    "roc, pr = plot_AUC_ROC_PR('LGBMClassifier_V5_'+'Admin_Hospi', clf, X_test, y_test)\n",
    "t1, t2 = Interval(y_test, y_model, alpha = 5.0)\n",
    "print(t1, t2)\n",
    "record = pd.read_excel('outputs/Tabla_Resultados.xlsx', engine='openpyxl')\n",
    "run = {'Fecha_hora':pd.to_datetime('today'),\n",
    "       'Tamaño_test': X_test.shape, #i,\n",
    "       'Dependiente':'ICU_QX',\n",
    "       'Modelo': 'LGBMClassifier_V6_ROS',#u,\n",
    "       'Parametros': model.best_params_,\n",
    "       'ROC_AUC_train': model.best_score_,\n",
    "       'ROC_AUC_Score': roc,\n",
    "       'Intervalo_ROC_AUC':t1, \n",
    "       'PR_AUC_Score': pr,\n",
    "       'Intervalo_PR_AUC':t2,\n",
    "       'f1_score': f1_score(y_test, y_model), \n",
    "       'Accuracy': accuracy_score(y_test, y_model),\n",
    "       'balanced_accuracy': balanced_accuracy_score(y_test, y_model),\n",
    "      }\n",
    "record = record.append(run, ignore_index=True)\n",
    "record.to_excel('outputs/Tabla_Resultados.xlsx', index=False)\n",
    "plot_confusion_matrix(clf, X_test, y_test, normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dutch-handling",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y = df_2['ICU_QX']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_resampled, y_resampled = SMOTE().fit_resample(X_train, y_train)\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(X_train.shape, X_resampled.shape)\n",
    "\n",
    "model = BayesSearchCV(LGBMClassifier(),\n",
    "                      espacio,\n",
    "                      scoring='roc_auc',\n",
    "                      n_points= 5,\n",
    "                      n_iter= 50,\n",
    "                      cv= 5,\n",
    "                      verbose = 0,\n",
    "                      n_jobs=6,\n",
    "                      random_state= 88)\n",
    "model.fit(X_resampled, y_resampled)\n",
    "clf = model.best_estimator_\n",
    "y_model = pd.Series(clf.predict(X_test), index=X_test.index)\n",
    "roc, pr = plot_AUC_ROC_PR('LGBMClassifier_V5_'+'Admin_Hospi', clf, X_test, y_test)\n",
    "t1, t2 = Interval(y_test, y_model, alpha = 5.0)\n",
    "print(t1, t2)\n",
    "record = pd.read_excel('outputs/Tabla_Resultados.xlsx', engine='openpyxl')\n",
    "run = {'Fecha_hora':pd.to_datetime('today'),\n",
    "       'Tamaño_test': X_test.shape, #i,\n",
    "       'Dependiente':'ICU_QX',\n",
    "       'Modelo': 'LGBMClassifier_V6_SMOTE',#u,\n",
    "       'Parametros': model.best_params_,\n",
    "       'ROC_AUC_train': model.best_score_,\n",
    "       'ROC_AUC_Score': roc,\n",
    "       'Intervalo_ROC_AUC':t1, \n",
    "       'PR_AUC_Score': pr,\n",
    "       'Intervalo_PR_AUC':t2,\n",
    "       'f1_score': f1_score(y_test, y_model), \n",
    "       'Accuracy': accuracy_score(y_test, y_model),\n",
    "       'balanced_accuracy': balanced_accuracy_score(y_test, y_model),\n",
    "      }\n",
    "record = record.append(run, ignore_index=True)\n",
    "record.to_excel('outputs/Tabla_Resultados.xlsx', index=False)\n",
    "plot_confusion_matrix(clf, X_test, y_test, normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empirical-chassis",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_2['ICU_QX']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_resampled, y_resampled = ADASYN().fit_resample(X_train, y_train)\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(X_train.shape, X_resampled.shape)\n",
    "\n",
    "model = BayesSearchCV(LGBMClassifier(),\n",
    "                      espacio,\n",
    "                      scoring='roc_auc',\n",
    "                      n_points= 5,\n",
    "                      n_iter= 50,\n",
    "                      cv= 5,\n",
    "                      verbose = 0,\n",
    "                      n_jobs=6,\n",
    "                      random_state= 88)\n",
    "model.fit(X_resampled, y_resampled)\n",
    "clf = model.best_estimator_\n",
    "y_model = pd.Series(clf.predict(X_test), index=X_test.index)\n",
    "roc, pr = plot_AUC_ROC_PR('LGBMClassifier_V5_'+'Admin_Hospi', clf, X_test, y_test)\n",
    "t1, t2 = Interval(y_test, y_model, alpha = 5.0)\n",
    "print(t1, t2)\n",
    "record = pd.read_excel('outputs/Tabla_Resultados.xlsx', engine='openpyxl')\n",
    "run = {'Fecha_hora':pd.to_datetime('today'),\n",
    "       'Tamaño_test': X_test.shape, #i,\n",
    "       'Dependiente':'Admin_Hospi',\n",
    "       'Modelo': 'LGBMClassifier_V6_ADASYN',#u,\n",
    "       'Parametros': model.best_params_,\n",
    "       'ROC_AUC_train': model.best_score_,\n",
    "       'ROC_AUC_Score': roc,\n",
    "       'Intervalo_ROC_AUC':t1, \n",
    "       'PR_AUC_Score': pr,\n",
    "       'Intervalo_PR_AUC':t2,\n",
    "       'f1_score': f1_score(y_test, y_model), \n",
    "       'Accuracy': accuracy_score(y_test, y_model),\n",
    "       'balanced_accuracy': balanced_accuracy_score(y_test, y_model),\n",
    "      }\n",
    "record = record.append(run, ignore_index=True)\n",
    "record.to_excel('outputs/Tabla_Resultados.xlsx', index=False)\n",
    "plot_confusion_matrix(clf, X_test, y_test, normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-explorer",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df['Destino']\n",
    "tfidf = TfidfVectorizer(encoding='utf-8',\n",
    "                        ngram_range=(1,1),\n",
    "                        stop_words=None,\n",
    "                        lowercase=False,\n",
    "                        max_df=1.,\n",
    "                        min_df=10,\n",
    "                        max_features=1000,\n",
    "                        norm='l2',\n",
    "                        sublinear_tf=True)\n",
    "# se aplica el TFIDF\n",
    "features = tfidf.fit_transform(df['chiefcomplaint']).toarray()\n",
    "\n",
    "from sklearn.feature_selection import chi2\n",
    "for category_id in sorted(labels.unique()):\n",
    "    features_chi2 = chi2(features, labels == category_id)\n",
    "    indices = np.argsort(features_chi2[0])\n",
    "    feature_names = np.array(tfidf.get_feature_names())[indices]\n",
    "    unigrams = [v for v in feature_names if len(v.split(' '))==1]\n",
    "    print('DESTINO {}:'.format(category_id))\n",
    "    print('Unigramas más correlacionados:\\n{}'.format(\"', '\".join(unigrams[-100:])))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stunning-lotus",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df['Admin_Hospi']\n",
    "from sklearn.feature_selection import chi2\n",
    "for category_id in sorted(labels.unique()):\n",
    "    features_chi2 = chi2(features, labels == category_id)\n",
    "    indices = np.argsort(features_chi2[0])\n",
    "    feature_names = np.array(tfidf.get_feature_names())[indices]\n",
    "    unigrams = [v for v in feature_names if len(v.split(' '))==1]\n",
    "    print('DESTINO {}:'.format(category_id))\n",
    "    print('Unigramas más correlacionados:\\n{}'.format(\"', '\".join(unigrams[-50:])))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entertaining-hospital",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = pd.DataFrame(features, index= df.index, columns=tfidf.get_feature_names())\n",
    "df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-making",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Hospitalization']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "model = LGBMClassifier(learning_rate= 0.07435133934470071, max_depth=4, n_estimators=3000, num_leaves= 500, subsample=0.6586814364523186)\n",
    "model.fit(X_train, y_train)\n",
    "y_model = pd.Series(model.predict(X_test), index=X_test.index)\n",
    "f1_score(y_test, y_model), accuracy_score(y_test, y_model), roc_auc_score(y_test, y_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "athletic-newspaper",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import plot_importance\n",
    "plot_importance(model, figsize=(10,35))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effective-boundary",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {'solver':['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "             'multi_class': ['ovr'],\n",
    "             'max_iter': np.arange(1,1000)}\n",
    "n_iter_search = 100\n",
    "model = RandomizedSearchCV(LogisticRegression(),\n",
    "                               param_distributions=param_dist,\n",
    "                               n_iter=n_iter_search,\n",
    "                               cv=5, scoring='roc_auc',\n",
    "                               n_jobs=-1,\n",
    "                               verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "matched-personality",
   "metadata": {},
   "source": [
    "Feature engineering\n",
    "marcación reingreso <72 horas\n",
    "número de signos anormales\n",
    "dummies anormales por signo vital\n",
    "admisiones previas\n",
    "\n",
    "\n",
    "Otros:\n",
    "triage\n",
    "examenes\n",
    "medicamientos\n",
    "diagnóstico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-thong",
   "metadata": {},
   "outputs": [],
   "source": [
    "clasificadores = {'Regresión Logística':LogisticRegression(),\n",
    "                  'Bosque aleatorio':RandomForestClassifier(),\n",
    "                  'Potenciación del Gradiente':LGBMClassifier()}\n",
    "espacios = {LogisticRegression():{},\n",
    "            RandomForestClassifier():{},\n",
    "            LGBMClassifier():{\"n_estimators\": Integer(10, 3000),\n",
    "                              'max_depth':Integer(1, 40),\n",
    "                              'num_leaves': Integer(2, 500),\n",
    "                              'learning_rate': Real(0.001, 0.3, prior='uniform'),\n",
    "                              'subsample':Real(0.2, 1, prior='uniform')},}\n",
    "\n",
    "pruebas = [0.9, 0.8] #[0.5, 0.4, 0.3, 0.2]\n",
    "for i in pruebas:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=i, random_state=88)\n",
    "    for u, v in clasificadores:\n",
    "        # Se realiza el ajuste de hiperparametros\n",
    "        model = BayesSearchCV(clasificadores[u], espacios[u],\n",
    "                              n_points= 5,\n",
    "                              n_iter= 50,\n",
    "                              cv= 5,\n",
    "                              verbose = 0,\n",
    "                              n_jobs=-1, random_state= 88)\n",
    "        # Se entrena el modelo\n",
    "        model.fit(X_train, y_train)\n",
    "        # Se extrae el mejor\n",
    "        clf = model.best_estimator_\n",
    "        y_model = clf.predict(X_test)\n",
    "        # Guardo los gráficos de ROC y PR\n",
    "        roc, pr = plot_AUC_ROC_PR(u+'_'+str(i), clf, X_test, y_test)\n",
    "        \n",
    "        record = pd.read_excel('outputs/Tabla_Resultados.xlsx', engine='openpyxl')\n",
    "        run = {'Fecha_hora':pd.to_datetime('today'),\n",
    "               'Tamaño_test': i,\n",
    "               'Modelo': u,\n",
    "               'Parametros': model.best_params_,\n",
    "               'ROC_AUC_train': model.best_score_,\n",
    "               'ROC_AUC_Score': roc,\n",
    "               'PR_AUC_Score': pr\n",
    "              }\n",
    "        record = record.append(run, ignore_index=True)\n",
    "        record.to_excel('outputs/Tabla_Resultados.xlsx', index=False)\n",
    "\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operating-negative",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['Hospitalization', 'ICU', 'Surgery']:\n",
    "    print(i)\n",
    "    y = df[i]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    print(X_train.shape)\n",
    "    print(X_test.shape)\n",
    "    model = BayesSearchCV(LGBMClassifier(),\n",
    "                          scoring='roc_auc',\n",
    "                          espacio,\n",
    "                          n_points= 5,\n",
    "                          n_iter= 50,\n",
    "                          cv= 5,\n",
    "                          verbose = 0,\n",
    "                          n_jobs=6,\n",
    "                          random_state= 88)\n",
    "    model.fit(X_train, y_train)\n",
    "    clf = model.best_estimator_\n",
    "    y_model = pd.Series(clf.predict(X_test), index=X_test.index)\n",
    "    roc, pr = plot_AUC_ROC_PR('LGBMClassifier_V5_'+i, clf, X_test, y_test)\n",
    "    t1, t2 = Interval(y_test, y_model, alpha = 5.0)\n",
    "    print(t1, t2)\n",
    "    record = pd.read_excel('outputs/Tabla_Resultados.xlsx', engine='openpyxl')\n",
    "    run = {'Fecha_hora':pd.to_datetime('today'),\n",
    "           'Tamaño_test': X_test.shape, #i,\n",
    "           'Dependiente':i,\n",
    "           'Modelo': 'LGBMClassifier_V5',#u,\n",
    "           'Parametros': model.best_params_,\n",
    "           'ROC_AUC_train': model.best_score_,\n",
    "           'ROC_AUC_Score': roc,\n",
    "           'Intervalo_ROC_AUC':t1, \n",
    "           'PR_AUC_Score': pr,\n",
    "           'Intervalo_PR_AUC':t2,\n",
    "           'f1_score': f1_score(y_test, y_model), \n",
    "           'Accuracy': accuracy_score(y_test, y_model),\n",
    "           'balanced_accuracy': balanced_accuracy_score(y_test, y_model),\n",
    "          }\n",
    "    record = record.append(run, ignore_index=True)\n",
    "    record.to_excel('outputs/Tabla_Resultados.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
